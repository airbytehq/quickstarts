{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f104c9d-933a-45fd-9d2c-57e6d56a56b1",
   "metadata": {},
   "source": [
    "# End-to-End RAG Tutorial Using GoogleDrive, PyAirbyte, Pinecone, and LangChain\n",
    "\n",
    "This notebook demonstrates an end-to-end Retrieval-Augmented Generation (RAG) pipeline. We will extract data from Google Drive using PyAirbyte, store it in a Pinecone vector store, and then use LangChain to perform RAG on the stored data. This workflow showcases how to integrate these tools to build a scalable RAG system.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **GoogleDrive**:\n",
    "   - Follow the instructions in the [GoogleDrive Source Connector Documentation](https://docs.airbyte.com/integrations/sources/google-drive) to set up your google-drive and obtain the service account json\n",
    "\n",
    "2. **Pinecone Account**:\n",
    "   - **Create a Pinecone Account**: Sign up for an account on the [Pinecone website](https://www.pinecone.io/).\n",
    "   - **Obtain Pinecone API Key**: Generate a new API key from your Pinecone project settings. For detailed instructions, refer to the [Pinecone documentation](https://docs.pinecone.io/docs/quickstart).\n",
    "\n",
    "3. **OpenAI API Key**:\n",
    "   - **Create an OpenAI Account**: Sign up for an account on [OpenAI](https://www.openai.com/).\n",
    "   - **Generate an API Key**: Go to the API section and generate a new API key. For detailed instructions, refer to the [OpenAI documentation](https://beta.openai.com/docs/quickstart).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1d3a0b-d446-43b0-b9dd-691fd837e5eb",
   "metadata": {},
   "source": [
    "## Install PyAirbyte and other dependencies"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ffebf71e-2b9a-4a1a-b448-9812b49f120c",
   "metadata": {},
   "source": [
    "!pip3 install airbyte openai langchain pinecone-client langchain-openai langchain-pinecone langchainhub "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b51a295-8c8e-483d-a931-24ec2590dffa",
   "metadata": {},
   "source": [
    "## Setup Source GoogleDrive with PyAirbyte\n",
    "\n",
    "The provided code configures an Airbyte source to extract data from an GoogleDrive Folder contains CSV file named NFLX.csv\n",
    "\n",
    "To configure according to your requirements, you can refer to [this references](https://docs.airbyte.com/integrations/sources/google-drive#reference).\n",
    "\n",
    "Note: The credentials are retrieved securely using the get_secret() method. This will automatically locate a matching Google Colab secret or environment variable, ensuring they are not hard-coded into the notebook. Make sure to add your key to the Secrets section on the left.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ddd2f96-8680-4a19-a02b-32fd0b703912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the value for secret 'service_json':  ········\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Connection check succeeded for `source-google-drive`.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Connection check succeeded for `source-google-drive`.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import airbyte as ab\n",
    "\n",
    "service_json = ab.get_secret('service_json')\n",
    "\n",
    "source = ab.get_source(\n",
    "    \"source-google-drive\",\n",
    "    install_if_missing=True,\n",
    "    config={\n",
    "        \"folder_url\": \"https://drive.google.com/drive/folders/1txtyBv_mfXYjn0R_-oxV3Vg5QOi-6XaI\",\n",
    "         \"credentials\": {\n",
    "             \"auth_type\": \"Service\",\n",
    "             \"service_account_info\": f\"\"\"{service_json}\"\"\",\n",
    "         },\n",
    "        \"streams\": [{\n",
    "                      \"name\": \"NFLX\",\n",
    "                      \"globs\": [\"**/*.csv\"],\n",
    "                      \"format\": {\n",
    "                        \"filetype\": \"csv\"\n",
    "                       },\n",
    "                      \"validation_policy\": \"Emit Record\",\n",
    "                      \"days_to_sync_if_history_is_full\": 3\n",
    "             }]\n",
    "                 \n",
    "         },\n",
    "    \n",
    ")\n",
    "\n",
    "# Verify the config and creds by running `check`:\n",
    "source.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12930b8-ff69-46e9-9daf-89b5ed49b68c",
   "metadata": {},
   "source": [
    "This is a basic process of fetching data from a Google Drive CSV source using Airbyte and converting it into a list of document objects, making it suitable for further processing or analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8abe757-b263-4574-b220-da715c4d827e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Read Progress\n",
       "\n",
       "Started reading at 11:20:50.\n",
       "\n",
       "Read **0** records over **2 seconds** (0.0 records / second).\n",
       "\n",
       "Finished reading at 11:20:53.\n",
       "\n",
       "Started finalizing streams at 11:20:53.\n",
       "\n",
       "Finalized **0** batches over 0 seconds.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "------------------------------------------------\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed `source-google-drive` read operation at <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:50:53</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed `source-google-drive` read operation at \u001b[1;92m16:50:53\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```yaml\n",
      "_ab_source_file_last_modified: '2024-06-04T04:00:24.000000Z'\n",
      "_ab_source_file_url: NFLX.csv\n",
      "_airbyte_extracted_at: 2024-06-07 11:20:25.946000\n",
      "_airbyte_meta: {}\n",
      "_airbyte_raw_id: 01HZS6VC3573GHEKRHMW1KA41T\n",
      "adj_close: '254.259995'\n",
      "close: '254.259995'\n",
      "date: '2018-02-05'\n",
      "high: '267.899994'\n",
      "low: '250.029999'\n",
      "open: '262.000000'\n",
      "volume: '11896100'\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This code reads data from a Google Drive CSV source and converts it into a list of document objects.\n",
    "\n",
    "source.select_all_streams()  # Select all streams from the Google Drive source\n",
    "read_result = source.read()  # Read the data from the selected streams\n",
    "documents_list = []\n",
    "\n",
    "# Convert the read data into document objects and add them to the list\n",
    "for key, value in read_result.items():\n",
    "    docs = value.to_documents()\n",
    "    for doc in docs:\n",
    "        documents_list.append(doc)\n",
    "\n",
    "# Print the Single row of the csv \n",
    "print(str(documents_list[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04c48f5-1801-47b9-9244-1cf1b560c291",
   "metadata": {},
   "source": [
    "## Use Langchain to build a RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebef2365-3570-43ad-b05d-a9e3ef86aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RecursiveCharacterTextSplitter from the langchain library to split documents into smaller chunks of 512 characters with a 50-character overlap.\n",
    "It then converts all metadata values in each chunk to strings and prints the total number of created document chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81cada6b-c1bb-4cbf-9a40-30f2547ed15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1009 document chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.utils import filter_complex_metadata\n",
    "\n",
    "\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50)\n",
    "chunked_docs = splitter.split_documents(documents_list)\n",
    "chunked_docs = filter_complex_metadata(chunked_docs)\n",
    "print(f\"Created {len(chunked_docs)} document chunks.\")\n",
    "\n",
    "for doc in chunked_docs:\n",
    "    for md in doc.metadata:\n",
    "        doc.metadata[md] = str(doc.metadata[md])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50b756b3-745b-49ff-a57a-d1d6371243fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "## Create Embeddings using HuggingFace sentence-transformers/all-mpnet-base-v2 model\n",
    "embeddings=HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c36b1f-f03b-4f78-bbe1-9e9035af5a1d",
   "metadata": {},
   "source": [
    "## Setting up Pinecone\n",
    "Pinecone is a managed vector database service designed for fast similarity search and real-time recommendation systems, offering scalability, efficiency, and ease of integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a61ce285-9d58-43e0-808b-786803364d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "os.environ['PINECONE_API_KEY'] = ab.get_secret(\"PINECONE_API_KEY\")\n",
    "index_name = \"gdriveairbyteindex\"\n",
    "\n",
    "pc = Pinecone()\n",
    "\n",
    "# Create pinecone index if not exists otherwise skip this step\n",
    "if not (pc.list_indexes()[0]['name'] == index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=768, \n",
    "        metric=\"cosine\", \n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        ) \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92f6e244-302b-4b6e-b490-3678412ba589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 1009}},\n",
       " 'total_vector_count': 1009}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2034d80-b359-4240-a695-c959619fae4a",
   "metadata": {},
   "source": [
    "## PineconeVectorStore\n",
    "PineconeVectorStore to store and index high-dimensional vectors extracted from documents, leveraging embeddings provided by Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "874ddc8a-035e-436c-8a14-a7ed24fc4adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "pinecone = PineconeVectorStore.from_documents(\n",
    "    chunked_docs, embedding=embeddings, index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e9990b-4982-44b6-9163-b12a3109e741",
   "metadata": {},
   "source": [
    "## RAG\n",
    "Retrieval Augumented Generation provides the Large Language Model (LLM) the context and ask the Large Language Model (LLM) to use the context to generate the response.\n",
    "\n",
    "This RAG implementation uses the vector databases to the store the text doc embeddings (generated from the data from your knowledge base) and based on the given query, this code retreives the relevant information from the pinecone vector database and add that text context to your prompt. This will be used by the llm to generate the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6d3490a-40e9-48d5-a8f1-5e6571f7e036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langchain RAG pipeline set up successfully.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = ab.get_secret(\"OPENAI_API_KEY\")\n",
    "\n",
    "retriever = pinecone.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(\"Langchain RAG pipeline set up successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f059fe04-bf3a-4bd8-b674-1f421f3bb5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The source data is about stock market information for Netflix (NFLX) on different dates, including details like opening price, closing price, high, low, adjusted close, and volume traded. The data includes specific dates ranging from 2018-10-31 to 2019-10-18. The information is extracted from a CSV file named NFLX.csv.\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke(\"What is the source data about?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gdriveenv)",
   "language": "python",
   "name": ".venv-source-google-drive"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
