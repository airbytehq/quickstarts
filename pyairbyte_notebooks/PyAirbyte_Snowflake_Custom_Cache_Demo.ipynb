{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8XtHKK4PujA"
      },
      "source": [
        "# PyAirbyte Custom Snowflake Cache Demo\n",
        "\n",
        "In this demo, we use PyAirbyte to ingest cryptocurrency data from [CoinAPI.io](https://www.coinapi.io/) into Snowflake.\n",
        "\n",
        "### Prerequisites\n",
        "- CoinAPI [API key](https://www.coinapi.io/get-free-api-key?product_id=market-data-api).\n",
        "- A Snowflake account with a database configured to work with PyAirbyte. Find specific details around config in our [documentation](https://docs.airbyte.com/integrations/destinations/snowflake)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyxh2NLuQJUf"
      },
      "source": [
        "## Install PyAirbyte\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DEgu1WpQNt-"
      },
      "outputs": [],
      "source": [
        "# Add virtual environment support for running in Google Colab\n",
        "!apt-get install -qq python3.10-venv\n",
        "\n",
        "# Install PyAirbyte\n",
        "%pip install --quiet airbyte"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwSqhsrmgcQ4"
      },
      "source": [
        "## Define a Snowflake Cache\n",
        "\n",
        "Define a PyAirbyte Cache for Snowflake."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJeZN6phg-1v"
      },
      "outputs": [],
      "source": [
        "from airbyte.caches import SnowflakeCache\n",
        "from google.colab import userdata\n",
        "\n",
        "# Define a Snowflake Cache and pass the necessary configuration\n",
        "sf_cache = SnowflakeCache(\n",
        "      account=userdata.get(\"SNOWFLAKE_ACCOUNT\"),\n",
        "      username=userdata.get(\"SNOWFLAKE_USERNAME\"),\n",
        "      password=userdata.get(\"SNOWFLAKE_PASSWORD\"),\n",
        "      warehouse=\"AIRBYTE_DEVELOP_WAREHOUSE\",\n",
        "      database=\"AIRBYTE_DEVELOP\",\n",
        "      role=\"AIRBYTE_DEVELOPER\",\n",
        "      schema_name=\"PYAIRBYTE_DEMO\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWWeEbTVEDFz"
      },
      "source": [
        "## Load the Source Data using PyAirbyte\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PhfWpS8QVzE"
      },
      "source": [
        "In this section, we establish a connection to CoinAPI.io to access cryptocurrency data via PyAirbyte. The connector is configured with necessary parameters like the API key, environment setting, symbol ID for the specific cryptocurrency index (in this case, COINBASE_SPOT_INDEX_USD), and the data period we are interested in. Check [the docs](https://docs.airbyte.com/integrations/sources/coin-api) for more details.\n",
        "\n",
        "We select all available streams for the source, which you can consult using the `get_available_streams()` method, or the docs. Then, we proceed to read from the source into Snowflake."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BI9hIeUvxXE"
      },
      "outputs": [],
      "source": [
        "import airbyte as ab\n",
        "\n",
        "# Configure and read from the source\n",
        "read_result = ab.get_source(\n",
        "    \"source-coin-api\",\n",
        "    config={\n",
        "          \"api_key\": userdata.get(\"API_KEY\"),\n",
        "          \"environment\": \"production\",\n",
        "          \"symbol_id\": \"COINBASE_SPOT_INDEX_USD\",\n",
        "          \"period\": \"1DAY\",\n",
        "          \"start_date\": \"2023-01-01T00:00:00\"\n",
        "    },\n",
        "    streams=[\"ohlcv_historical_data\", \"trades_historical_data\", \"quotes_historical_data\"],\n",
        ").read(cache=sf_cache)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPcaLfSCYrdo"
      },
      "source": [
        "## Read data from Snowflake\n",
        "\n",
        "Read from the already-written Snowflake table into a pandas Dataframe. After the data is in the cache, you can read it without re-configuring or re-creating the source object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "z-nOAXR6Y-ui"
      },
      "outputs": [],
      "source": [
        "# Read from the cache into a pandas Dataframe:\n",
        "ohlcv_df = read_result[\"ohlcv_historical_data\"].to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6cMu9G2ZVxK"
      },
      "source": [
        "## Run data transformations\n",
        "\n",
        "- Convert `time_period_start` to datetime for easy handling of dates.\n",
        "- Convert numeric columns to numeric types for calculations.\n",
        "- Calculate `daily_movement` to analyze daily price changes in the market."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hmRZZ5PsZYVW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert 'time_period_start' to datetime format and necessary columns to numeric\n",
        "ohlcv_df['time_period_start'] = pd.to_datetime(ohlcv_df['time_period_start'])\n",
        "numeric_columns = ['price_open', 'price_high', 'price_low', 'price_close', 'volume_traded', 'trades_count']\n",
        "ohlcv_df[numeric_columns] = ohlcv_df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Calculate daily price movement\n",
        "ohlcv_df['daily_movement'] = ohlcv_df['price_close'] - ohlcv_df['price_open']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knjH8Cx_zyCa"
      },
      "source": [
        "## Write Dataframe to Snowflake\n",
        "\n",
        "Get a SQL engine from the Snowflake cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dsn6JSZzfBBw"
      },
      "outputs": [],
      "source": [
        "engine = sf_cache.get_sql_engine()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhTzao0y0ObW"
      },
      "source": [
        "Now, we can write our transformed Dataframe back to Snowflake in a new table called `daily_movement`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gy1TzBf-f6If"
      },
      "outputs": [],
      "source": [
        "from snowflake.connector.pandas_tools import pd_writer\n",
        "\n",
        "ohlcv_df.to_sql('daily_movement', engine, index=False, method=pd_writer, if_exists='replace')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
