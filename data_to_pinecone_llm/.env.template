# TEMPLATE FILE
# -------------------
# Before using this file, copy its contents to a new file
# called `.env` (removing the `.template` suffix).
# -------------------
# To load these into a bash terminal, change to the parent directory
# and execute this command:
#    set -o allexport && source .env && set +o allexport
#
# Terraform variables are provided in the form `TF_VAR_{setting_name}={setting_value}`

# Pinecone Config
PINECONE_ENVIRONMENT=_pinecone_environment_
PINECONE_INDEX=_pinecone_index_
TF_VAR_pinecone_environment=${PINECONE_ENVIRONMENT}
TF_VAR_pinecone_index=${PINECONE_INDEX}

# BigQuery project info
BIGQUERY_PROJECT_ID="_project_id_"
BIGQUERY_DATASET_ID="${BIGQUERY_PROJECT_ID}._dataset_id_"
BIGQUERY_DATASET_LOCATION="us-west1"
TF_VAR_bigquery_project_id=${BIGQUERY_PROJECT_ID}
TF_VAR_bigquery_dataset_id=${BIGQUERY_DATASET_ID}
TF_VAR_bigquery_dataset_location=${BIGQUERY_DATASET_LOCATION}

# BigQuery creds file (TODO: update to match your file path)
DBT_BIGQUERY_KEYFILE_PATH=/workspaces/quickstarts/data_to_pinecone_llm/secrets/google-bigquery-creds.json
TF_VAR_bigquery_credentials_json_file_path=${DBT_BIGQUERY_KEYFILE_PATH}

# Airbyte secrets
TF_VAR_airbyte_workspace_id=_workspace_id_
TF_VAR_airbyte_cloud_auth_key="_bearer_auth_key"

# Pinecone secrets
PINECONE_KEY=_pinecone_key_
TF_VAR_pinecone_key=${PINECONE_KEY}

# OpenAI secrets
OPENAI_API_KEY=_openai_api_key_
TF_VAR_openai_key=${OPENAI_API_KEY}

# Notion secrets
notion_token="_notion_token_"
