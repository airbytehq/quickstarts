{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Airbyte Snowflake Cortex RAG Demo\n",
        "\n",
        "This tutorial demonstrates how to use data stored in Airbyte's Snowflake Cortex destination to perform Retrieval-Augmented Generation (RAG). You should use this destination when you intend to use Snowflake for LLM specific vector operations like RAG.\n",
        "\n",
        "As a practical example, we'll build a Product Assistantâ€”an AI chatbot capable of answering product-related questions using data from multiple Airbyte-related sources. With the Product Assistant, you can ask questions across all your sales enablement data in one place.\n",
        "\n",
        "#### Prerequisites:\n",
        "* Vector data stored in Snowflake via Snowflake Cortex destination. In our case we are using data from airbyte docs, Github issues and Zendesk.\n",
        "* Snowflake account with Cortex functions enabled\n",
        "* Open AI key\n"
      ],
      "metadata": {
        "id": "KWKEgtakJtH6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS3oGgI0CVpn"
      },
      "source": [
        "### a. Install dependencies\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bM4Te8XEWECV"
      },
      "outputs": [],
      "source": [
        "# Add virtual environment support in Google Colab\n",
        "!apt-get install -qq python3.10-venv\n",
        "\n",
        "# Install openai\n",
        "# tbd - add snowflake python connector\n",
        "%pip install --quiet openai snowflake-connector-python langchain-openai tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. Explore data stored in Snowflake.\n",
        "\n",
        "Let's see what document/vecto data in Snowflake looks like."
      ],
      "metadata": {
        "id": "nKbdq1eUcmAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch data from airbyte_docs table\n",
        "from snowflake import connector\n",
        "from google.colab import userdata\n",
        "from typing import List\n",
        "import pandas as pd\n",
        "\n",
        "def get_db_connection():\n",
        "    return connector.connect(\n",
        "        account=userdata.get(\"SNOWFLAKE_HOST\"),\n",
        "        role=userdata.get(\"SNOWFLAKE_ROLE\"),\n",
        "        warehouse=userdata.get(\"SNOWFLAKE_WAREHOUSE\"),\n",
        "        database=userdata.get(\"SNOWFLAKE_DATABASE\"),\n",
        "        schema=userdata.get(\"SNOWFLAKE_SCHEMA\"),\n",
        "        user=userdata.get(\"SNOWFLAKE_USERNAME\"),\n",
        "        password=userdata.get(\"SNOWFLAKE_PASSWORD\"),\n",
        "    )\n",
        "\n",
        "def fetch_table_data(table_name, columns):\n",
        "    conn = get_db_connection()\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Form the query to select specific columns\n",
        "    columns_str = \", \".join(columns)\n",
        "    query = f\"SELECT {columns_str} FROM {table_name};\"\n",
        "\n",
        "    cursor.execute(query)\n",
        "    result = cursor.fetchall()\n",
        "\n",
        "    # Fetch the column names\n",
        "    col_names = [desc[0] for desc in cursor.description]\n",
        "\n",
        "    cursor.close()\n",
        "    conn.close()\n",
        "\n",
        "    # Load the result into a pandas DataFrame\n",
        "    df = pd.DataFrame(result, columns=col_names)\n",
        "    return df;\n",
        "\n",
        "# show data from airbtye_docs table\n",
        "data_frame = fetch_table_data(\"airbyte_docs\", [\"document_id\", \"document_content\", \"metadata\", \"embedding\"])\n",
        "data_frame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TKDGBUhLcfuK",
        "outputId": "1231d559-298f-43a0-95c3-a67f8cfb62ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   DOCUMENT_ID  \\\n",
              "0  Stream_airbyte_docs_Key_snowflake-cortex.md   \n",
              "1  Stream_airbyte_docs_Key_snowflake-cortex.md   \n",
              "\n",
              "                                    DOCUMENT_CONTENT  \\\n",
              "0  content: # Snowflake Cortex Destination\\n\\n## ...   \n",
              "1  1. OpenAI - using [OpenAI API](https://beta.op...   \n",
              "\n",
              "                                            METADATA  \\\n",
              "0  {\\n  \"_ab_source_file_last_modified\": \"2024-05...   \n",
              "1  {\\n  \"_ab_source_file_last_modified\": \"2024-05...   \n",
              "\n",
              "                                           EMBEDDING  \n",
              "0  [-0.015022738836705685, 0.01687774434685707, -...  \n",
              "1  [-0.021381134167313576, -0.005535035394132137,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e6015f9-09bc-41bb-a167-de4813387434\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DOCUMENT_ID</th>\n",
              "      <th>DOCUMENT_CONTENT</th>\n",
              "      <th>METADATA</th>\n",
              "      <th>EMBEDDING</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stream_airbyte_docs_Key_snowflake-cortex.md</td>\n",
              "      <td>content: # Snowflake Cortex Destination\\n\\n## ...</td>\n",
              "      <td>{\\n  \"_ab_source_file_last_modified\": \"2024-05...</td>\n",
              "      <td>[-0.015022738836705685, 0.01687774434685707, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Stream_airbyte_docs_Key_snowflake-cortex.md</td>\n",
              "      <td>1. OpenAI - using [OpenAI API](https://beta.op...</td>\n",
              "      <td>{\\n  \"_ab_source_file_last_modified\": \"2024-05...</td>\n",
              "      <td>[-0.021381134167313576, -0.005535035394132137,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e6015f9-09bc-41bb-a167-de4813387434')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1e6015f9-09bc-41bb-a167-de4813387434 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1e6015f9-09bc-41bb-a167-de4813387434');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9351cc7d-e406-4cda-b52e-fa01dc350bc8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9351cc7d-e406-4cda-b52e-fa01dc350bc8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9351cc7d-e406-4cda-b52e-fa01dc350bc8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_frame",
              "summary": "{\n  \"name\": \"data_frame\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"DOCUMENT_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Stream_airbyte_docs_Key_snowflake-cortex.md\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DOCUMENT_CONTENT\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1. OpenAI - using [OpenAI API](https://beta.openai.com/docs/api-reference/text-embedding) , the connector will produce embeddings using the `text-embedding-ada-002` model with **1536 dimensions**. This integration will be constrained by the [speed of the OpenAI embedding API](https://platform.openai.com/docs/guides/rate-limits/overview).\\n\\n2. Cohere - using the [Cohere API](https://docs.cohere.com/reference/embed), the connector will produce embeddings using the `embed-english-light-v2.0` model with **1024 dimensions**.\\n\\nFor testing purposes, it's also possible to use the [Fake embeddings](https://python.langchain.com/docs/modules/data_connection/text_embedding/integrations/fake) integration. It will generate random embeddings and is suitable to test a data pipeline without incurring embedding costs.\\n\\n### Indexing/Data Storage \\n\\nTo get started, sign up for [Snowflake](https://www.snowflake.com/en/). Ensure you have set a database, and a data wareshouse before running the Snowflake Cortex destination. All streams will be indexed/stored into a table with the same name. The table will be created if it doesn't exist. The table will have the following columns: \\n- document_id (string) - the unique identifier of the document, creating from appending the primary keys in the stream schema\\n- chunk_id (string) - the unique identifier of the chunk, created by appending the chunk number to the document_id\\n- metadata (variant) - the metadata of the document, stored as key-value pairs\\n- page_content (string) - the text content of the chunk\\n- embedding (vector) - the embedding of the chunk, stored as a list of floats\\n\\n\\n## CHANGELOG\\n\\n| Version | Date       | Pull Request                                                  | Subject                                                                                                                                              |\\n|:--------| :--------- |:--------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------|\\n| 0.1.2 | 2024-05-17 | [#38327](https://github.com/airbytehq/airbyte/pull/38327) | Fix chunking related issue.\\n| 0.1.1 | 2024-05-15 | [#38206](https://github.com/airbytehq/airbyte/pull/38206) | Bug fixes.\\n| 0.1.0 | 2024-05-13 | [#37333](https://github.com/airbytehq/airbyte/pull/36807) | Add support for Snowflake as a Vector destination.\\n\\ndocument_key: snowflake-cortex.md\\n_ab_source_file_parse_error: None\\n_ab_source_file_last_modified: 2024-05-17T19:53:48.000000Z\\n_ab_source_file_url: snowflake-cortex.md\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"METADATA\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{\\n  \\\"_ab_source_file_last_modified\\\": \\\"2024-05-17T19:53:48.000000Z\\\",\\n  \\\"_ab_source_file_parse_error\\\": null,\\n  \\\"_ab_source_file_url\\\": \\\"snowflake-cortex.md\\\",\\n  \\\"_ab_stream\\\": \\\"airbyte_docs\\\",\\n  \\\"content\\\": \\\"# Snowflake Cortex Destination\\\\n\\\\n## Overview\\\\n\\\\nThis page guides you through the process of setting up the [Snowflake](https://www.snowflake.com/en/) as a vector destination.\\\\n\\\\nThere are three parts to this:\\\\n* Processing - split up individual records in chunks so they will fit the context window and decide which fields to use as context and which are supplementary metadata.\\\\n* Embedding - convert the text into a vector representation using a pre-trained model (Currently, OpenAI's `text-embedding-ada-002` and Cohere's `embed-english-light-v2.0` are supported. Coming soon: Hugging Face's `e5-base-v2`).\\\\n* Indexing/Data storage - store the vectors in a vector (compatible) database for similarity search\\\\n\\\\n## Prerequisites\\\\n\\\\nTo use the Snowflake Cortex destination, you'll need:\\\\n\\\\n- An account with API access for OpenAI or Cohere (depending on which embedding method you want to use)\\\\n- A Snowflake account with support for vector type columns\\\\n\\\\nYou'll need the following information to configure the destination:\\\\n\\\\n- **Embedding service API Key** - The API key for your OpenAI or Cohere account\\\\n- **Snowflake Account** - The account name for your Snowflake account\\\\n- **Snowflake User** - The user name for your Snowflake account\\\\n- **Snowflake Password** - The password for your Snowflake account\\\\n- **Snowflake Database** - The database name in Snowflake to load data into\\\\n- **Snowflake Warehouse** - The warehouse name in Snowflake to use\\\\n- **Snowflake Role** - The role name in Snowflake to use. \\\\n\\\\n\\\\n## Features\\\\n\\\\n| Feature                        | Supported?           | Notes |\\\\n| :----------------------------- | :------------------- | :---- |\\\\n| Full Refresh Sync              | Yes                  |       |\\\\n| Incremental - Append Sync      | Yes                  |       |\\\\n| Incremental - Append + Deduped | Yes                  |       |\\\\n\\\\n## Data type mapping\\\\n\\\\nAll fields specified as metadata fields will be stored in the metadata object of the document and can be used for filtering. The following data types are allowed for metadata fields:\\\\n* String\\\\n* Number (integer or floating point, gets converted to a 64 bit floating point)\\\\n* Booleans (true, false)\\\\n* List of String\\\\n\\\\nAll other fields are ignored.\\\\n\\\\n## Configuration\\\\n\\\\n### Processing\\\\n\\\\nEach record will be split into text fields and meta fields as configured in the \\\\\\\"Processing\\\\\\\" section. All text fields are concatenated into a single string and then split into chunks of configured length. If specified, the metadata fields are stored as-is along with the embedded text chunks. Please note that meta data fields can only be used for filtering and not for retrieval and have to be of type string, number, boolean (all other values are ignored). Please note that there's a 40kb limit on the _total_ size of the metadata saved for each entry.  Options around configuring the chunking process use the [Langchain Python library](https://python.langchain.com/docs/get_started/introduction).\\\\n\\\\nWhen specifying text fields, you can access nested fields in the record by using dot notation, e.g. `user.name` will access the `name` field in the `user` object. It's also possible to use wildcards to access all fields in an object, e.g. `users.*.name` will access all `names` fields in all entries of the `users` array.\\\\n\\\\nThe chunk length is measured in tokens produced by the `tiktoken` library. The maximum is 8191 tokens, which is the maximum length supported by the `text-embedding-ada-002` model.\\\\n\\\\nThe stream name gets added as a metadata field `_ab_stream` to each document. If available, the primary key of the record is used to identify the document to avoid duplications when updated versions of records are indexed. It is added as the `_ab_record_id` metadata field.\\\\n\\\\n### Embedding\\\\n\\\\nThe connector can use one of the following embedding methods:\\\\n\\\\n1. OpenAI - using [OpenAI API](https://beta.openai.com/docs/api-reference/text-embedding) , the connector will produce embeddings using the `text-embedding-ada-002` model with **1536 dimensions**. This integration will be constrained by the [speed of the OpenAI embedding API](https://platform.openai.com/docs/guides/rate-limits/overview).\\\\n\\\\n2. Cohere - using the [Cohere API](https://docs.cohere.com/reference/embed), the connector will produce embeddings using the `embed-english-light-v2.0` model with **1024 dimensions**.\\\\n\\\\nFor testing purposes, it's also possible to use the [Fake embeddings](https://python.langchain.com/docs/modules/data_connection/text_embedding/integrations/fake) integration. It will generate random embeddings and is suitable to test a data pipeline without incurring embedding costs.\\\\n\\\\n### Indexing/Data Storage \\\\n\\\\nTo get started, sign up for [Snowflake](https://www.snowflake.com/en/). Ensure you have set a database, and a data wareshouse before running the Snowflake Cortex destination. All streams will be indexed/stored into a table with the same name. The table will be created if it doesn't exist. The table will have the following columns: \\\\n- document_id (string) - the unique identifier of the document, creating from appending the primary keys in the stream schema\\\\n- chunk_id (string) - the unique identifier of the chunk, created by appending the chunk number to the document_id\\\\n- metadata (variant) - the metadata of the document, stored as key-value pairs\\\\n- page_content (string) - the text content of the chunk\\\\n- embedding (vector) - the embedding of the chunk, stored as a list of floats\\\\n\\\\n\\\\n## CHANGELOG\\\\n\\\\n| Version | Date       | Pull Request                                                  | Subject                                                                                                                                              |\\\\n|:--------| :--------- |:--------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------|\\\\n| 0.1.2 | 2024-05-17 | [#38327](https://github.com/airbytehq/airbyte/pull/38327) | Fix chunking related issue.\\\\n| 0.1.1 | 2024-05-15 | [#38206](https://github.com/airbytehq/airbyte/pull/38206) | Bug fixes.\\\\n| 0.1.0 | 2024-05-13 | [#37333](https://github.com/airbytehq/airbyte/pull/36807) | Add support for Snowflake as a Vector destination.\\\\n\\\",\\n  \\\"document_key\\\": \\\"snowflake-cortex.md\\\"\\n}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EMBEDDING\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5LU0M4g6clBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c. Build the RAG pipeline and ask a question\n",
        "\n",
        "Let's write the three main pieces of a RAG pipeline:\n",
        "* Embedding incoming query\n",
        "* Doing similarity search to find matching chunks\n",
        "* Send chunks to LLM for completion"
      ],
      "metadata": {
        "id": "SyyzczWXBXTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from snowflake import connector\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from google.colab import userdata\n",
        "from typing import List\n",
        "from rich.console import Console\n",
        "\n",
        "def get_db_connection():\n",
        "    return connector.connect(\n",
        "        account=userdata.get(\"SNOWFLAKE_HOST\"),\n",
        "        role=userdata.get(\"SNOWFLAKE_ROLE\"),\n",
        "        warehouse=userdata.get(\"SNOWFLAKE_WAREHOUSE\"),\n",
        "        database=userdata.get(\"SNOWFLAKE_DATABASE\"),\n",
        "        schema=userdata.get(\"SNOWFLAKE_SCHEMA\"),\n",
        "        user=userdata.get(\"SNOWFLAKE_USERNAME\"),\n",
        "        password=userdata.get(\"SNOWFLAKE_PASSWORD\"),\n",
        "    )\n",
        "\n",
        "# convert user's query into a vector array to prep for similiary search\n",
        "def get_embedding_from_openai(query)->str:\n",
        "  print(f\"Embedding user's query -> {query}...\")\n",
        "  embeddings = OpenAIEmbeddings(openai_api_key=userdata.get(\"OPENAI_API_KEY\"))\n",
        "  return embeddings\n",
        "\n",
        "# use Snowflake's Cortex in-build similarity search to find matching chunks\n",
        "def get_similar_chunks_from_snowflake(query_vector, table_names) -> List[str]:\n",
        "        print(\"\\nRetrieving similar chunks...\")\n",
        "        conn = get_db_connection()\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        chunks = []\n",
        "        for table_name in table_names:\n",
        "            query = f\"\"\"\n",
        "            SELECT document_content,\n",
        "              VECTOR_COSINE_SIMILARITY(embedding, CAST({query_vector} AS VECTOR(FLOAT, 1536))) AS similarity\n",
        "            FROM {table_name}\n",
        "            ORDER BY similarity DESC\n",
        "            LIMIT 2\n",
        "            \"\"\"\n",
        "            cursor.execute(query)\n",
        "            result = cursor.fetchall()\n",
        "            print(f\"Found {len(result)} matching chunks in table:{table_name}!\")\n",
        "            chunks += [item[0] for item in result]\n",
        "        cursor.close()\n",
        "        conn.close()\n",
        "\n",
        "        return chunks\n",
        "\n",
        "# use Snowflake's Cortex in-build completion to find matching chunks.\n",
        "def get_completion_from_snowflake(question, document_chunks: List[str], model_name):\n",
        "        print(f\"\\nSending chunks to Snowflake (LLM: {model_name}) for completion...\")\n",
        "        conn = get_db_connection()\n",
        "        cur = conn.cursor()\n",
        "\n",
        "        chunks = \"\\n\\n\".join(document_chunks)\n",
        "\n",
        "        query = f\"\"\"\n",
        "        SELECT snowflake.cortex.complete(\n",
        "        '{model_name}',\n",
        "        CONCAT(\n",
        "            'You are an Airbyte product assistant. Answer the question based on the context. Do not use any other information. Be concise. When returning a list of items, please enumerate description on separate lines','Context: ',\n",
        "            $$\n",
        "            {chunks}\n",
        "            $$,\n",
        "        'Question: ',\n",
        "        $$ {question} $$,\n",
        "        'Answer: '\n",
        "        )\n",
        "        ) as response;\"\"\"\n",
        "        cur.execute(query)\n",
        "        result = cur.fetchall()\n",
        "        cur.close()\n",
        "        conn.close()\n",
        "        # TO-DO: better parsing here\n",
        "        return result[0][0].strip()\n",
        "\n",
        "# Putting it all together\n",
        "def get_response(query, table_names, model_name=\"llama2-70b-chat\"):\n",
        "        # Step 1: embed the query\n",
        "        embeddings = get_embedding_from_openai(query)\n",
        "\n",
        "        # Step 2: get similar chunks from sources/tables in Snowflake\n",
        "        chunks = get_similar_chunks_from_snowflake(embeddings.embed_query(query), table_names)\n",
        "\n",
        "        if (len(chunks) == 0):\n",
        "            return \"I am sorry, I do not have the context to answer your question.\"\n",
        "        else:\n",
        "            # Step 3: send chunks to LLM for completion\n",
        "            return get_completion_from_snowflake(query, chunks, model_name)\n",
        "\n",
        "# Ask a question\n",
        "query = 'How can I store vector data in Snowflake'\n",
        "response = get_response(query, [\"airbyte_docs\"], \"snowflake-arctic\")\n",
        "\n",
        "Console().print(f\"\\n\\nResponse from LLM:\\n\\n[blue]{response}[/blue]\")\n"
      ],
      "metadata": {
        "id": "zQ6rWEV2u-3U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "d364b7e3-cfca-4628-da20-3ae4f34ad143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding user's query -> How can I store vector data in Snowflake...\n",
            "\n",
            "Retrieving similar chunks...\n",
            "Found 2 matching chunks in table:airbyte_docs!\n",
            "\n",
            "Sending chunks to Snowflake (LLM: snowflake-arctic) for completion...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\n",
              "Response from LLM:\n",
              "\n",
              "\u001b[34mTo store vector data in Snowflake, you can use the Snowflake Cortex destination. This destination allows you to \u001b[0m\n",
              "\u001b[34mprocess, embed, and index/store vector data in Snowflake. You will need an account with API access for OpenAI or \u001b[0m\n",
              "\u001b[34mCohere, as well as a Snowflake account with support for vector type columns. The connector supports Full Refresh \u001b[0m\n",
              "\u001b[34mSync, Incremental - Append Sync, and Incremental - Append + Deduped. The data type mapping allows for String, \u001b[0m\n",
              "\u001b[34mNumber \u001b[0m\u001b[1;34m(\u001b[0m\u001b[34minteger or floating point\u001b[0m\u001b[1;34m)\u001b[0m\u001b[34m, Booleans \u001b[0m\u001b[1;34m(\u001b[0m\u001b[34mtrue, false\u001b[0m\u001b[1;34m)\u001b[0m\u001b[34m, and List of String for metadata fields. The table in \u001b[0m\n",
              "\u001b[34mSnowflake will have columns for document_id, chunk_id, metadata, page_content, and embedding.\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "Response from LLM:\n",
              "\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">To store vector data in Snowflake, you can use the Snowflake Cortex destination. This destination allows you to </span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">process, embed, and index/store vector data in Snowflake. You will need an account with API access for OpenAI or </span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">Cohere, as well as a Snowflake account with support for vector type columns. The connector supports Full Refresh </span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">Sync, Incremental - Append Sync, and Incremental - Append + Deduped. The data type mapping allows for String, </span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">Number </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080\">integer or floating point</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span><span style=\"color: #000080; text-decoration-color: #000080\">, Booleans </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080\">true, false</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span><span style=\"color: #000080; text-decoration-color: #000080\">, and List of String for metadata fields. The table in </span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">Snowflake will have columns for document_id, chunk_id, metadata, page_content, and embedding.</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### d. Let's ask another question\n",
        "\n"
      ],
      "metadata": {
        "id": "G5NvV86T57-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'What are the upcoming features for Snowflake Cortex?'\n",
        "response = get_response(query, [\"airbyte_github_issues\"])\n",
        "Console().print(f\"\\n\\nResponse from LLM:\\n\\n[blue]{response}[/blue]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "cPYdEs663tl8",
        "outputId": "6997984b-6ea3-4b95-d80f-ccace53b6d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding user's query -> What are the upcoming features for Snowflake Cortex?...\n",
            "\n",
            "Retrieving similar chunks...\n",
            "Found 2 matching chunks in table:airbyte_github_issues!\n",
            "\n",
            "Sending chunks to Snowflake (LLM: llama2-70b-chat) for completion...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\n",
              "Response from LLM:\n",
              "\n",
              "\u001b[34mBased on the information provided, there are two upcoming features for Snowflake Cortex:\u001b[0m\n",
              "\n",
              "\u001b[1;34m1\u001b[0m\u001b[34m. Add multiple authorization options for Snowflake Cortex connector.\u001b[0m\n",
              "\u001b[1;34m2\u001b[0m\u001b[34m. Add option for embedding using e5-base-v2 for Snowflake Cortex connector.\u001b[0m\n",
              "\n",
              "\u001b[34mThese features are currently in the planning stage and have been proposed by the user bindipankhudi. They are not \u001b[0m\n",
              "\u001b[34myet implemented and are still in the open state.\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "Response from LLM:\n",
              "\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">Based on the information provided, there are two upcoming features for Snowflake Cortex:</span>\n",
              "\n",
              "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080\">. Add multiple authorization options for Snowflake Cortex connector.</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">2</span><span style=\"color: #000080; text-decoration-color: #000080\">. Add option for embedding using e5-base-v2 for Snowflake Cortex connector.</span>\n",
              "\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">These features are currently in the planning stage and have been proposed by the user bindipankhudi. They are not </span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">yet implemented and are still in the open state.</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### e. Closing the loop\n",
        "Let's see if there are customers asking for upcoming features above."
      ],
      "metadata": {
        "id": "S_CJ3_C9pvw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'Are there customers asking for better authorization options for Snowflake Cortex? Give me their names and email.'\n",
        "response = get_response(query, [\"airbyte_zendesk_tickets\", \"airbyte_zendesk_users\"])\n",
        "Console().print(f\"\\n\\nResponse from LLM:\\n\\n[blue]{response}[/blue]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "mLfNlzGLqOIg",
        "outputId": "dcfa593f-dab0-44ff-fcec-e4cb671b6d1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding user's query -> Are there customers asking for better authorization options for Snowflake Cortex? Give me their names and email....\n",
            "\n",
            "Retrieving similar chunks...\n",
            "Found 2 matching chunks in table:airbyte_zendesk_tickets!\n",
            "Found 2 matching chunks in table:airbyte_zendesk_users!\n",
            "\n",
            "Sending chunks to Snowflake (LLM: llama2-70b-chat) for completion...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\n",
              "Response from LLM:\n",
              "\n",
              "\u001b[34mYes, there are customers asking for better authorization options for Snowflake Cortex. Here are their names and \u001b[0m\n",
              "\u001b[34memail addresses:\u001b[0m\n",
              "\n",
              "\u001b[1;34m1\u001b[0m\u001b[34m. Ping Sun - ping.sun@example.com\u001b[0m\n",
              "\u001b[1;34m2\u001b[0m\u001b[34m. Ram Saelim - ram.saelim@example.com\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "Response from LLM:\n",
              "\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">Yes, there are customers asking for better authorization options for Snowflake Cortex. Here are their names and </span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">email addresses:</span>\n",
              "\n",
              "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080\">. Ping Sun - ping.sun@example.com</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">2</span><span style=\"color: #000080; text-decoration-color: #000080\">. Ram Saelim - ram.saelim@example.com</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "nKbdq1eUcmAz"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}