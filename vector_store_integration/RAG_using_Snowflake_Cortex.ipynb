{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWKEgtakJtH6"
      },
      "source": [
        "## Airbyte Snowflake Cortex RAG Demo\n",
        "\n",
        "This tutorial demonstrates how to use data stored in Airbyte's Snowflake Cortex destination to perform Retrieval-Augmented Generation (RAG). You should use this destination when you intend to use Snowflake for LLM specific vector operations like RAG.\n",
        "\n",
        "As a practical example, we'll build a Product Assistantâ€”an AI chatbot capable of answering product-related questions using data from multiple Airbyte-related sources. With the Product Assistant, you can ask questions across all your sales enablement data in one place.\n",
        "\n",
        "#### Prerequisites:\n",
        "* Vector data stored in Snowflake via Snowflake Cortex destination. In our case we are using data from airbyte docs, Github issues and Zendesk.\n",
        "* Snowflake account with Cortex functions enabled\n",
        "* Open AI key\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS3oGgI0CVpn"
      },
      "source": [
        "### a. Install dependencies\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bM4Te8XEWECV"
      },
      "outputs": [],
      "source": [
        "# Add virtual environment support in Google Colab\n",
        "!apt-get install -qq python3.10-venv\n",
        "\n",
        "# Install openai\n",
        "# tbd - add snowflake python connector\n",
        "%pip install --quiet openai snowflake-connector-python langchain-openai tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKbdq1eUcmAz"
      },
      "source": [
        "### b. Explore data stored in Snowflake.\n",
        "\n",
        "Let's see what document/vecto data in Snowflake looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TKDGBUhLcfuK",
        "outputId": "1231d559-298f-43a0-95c3-a67f8cfb62ab"
      },
      "outputs": [],
      "source": [
        "# Fetch data from airbyte_docs table\n",
        "from snowflake import connector\n",
        "from google.colab import userdata\n",
        "from typing import List\n",
        "import pandas as pd\n",
        "\n",
        "def get_db_connection():\n",
        "    return connector.connect(\n",
        "        account=userdata.get(\"SNOWFLAKE_HOST\"),\n",
        "        role=userdata.get(\"SNOWFLAKE_ROLE\"),\n",
        "        warehouse=userdata.get(\"SNOWFLAKE_WAREHOUSE\"),\n",
        "        database=userdata.get(\"SNOWFLAKE_DATABASE\"),\n",
        "        schema=userdata.get(\"SNOWFLAKE_SCHEMA\"),\n",
        "        user=userdata.get(\"SNOWFLAKE_USERNAME\"),\n",
        "        password=userdata.get(\"SNOWFLAKE_PASSWORD\"),\n",
        "    )\n",
        "\n",
        "def fetch_table_data(table_name, columns):\n",
        "    conn = get_db_connection()\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Form the query to select specific columns\n",
        "    columns_str = \", \".join(columns)\n",
        "    query = f\"SELECT {columns_str} FROM {table_name};\"\n",
        "\n",
        "    cursor.execute(query)\n",
        "    result = cursor.fetchall()\n",
        "\n",
        "    # Fetch the column names\n",
        "    col_names = [desc[0] for desc in cursor.description]\n",
        "\n",
        "    cursor.close()\n",
        "    conn.close()\n",
        "\n",
        "    # Load the result into a pandas DataFrame\n",
        "    df = pd.DataFrame(result, columns=col_names)\n",
        "    return df;\n",
        "\n",
        "# show data from airbtye_docs table\n",
        "data_frame = fetch_table_data(\"airbyte_docs\", [\"document_id\", \"document_content\", \"metadata\", \"embedding\"])\n",
        "data_frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LU0M4g6clBj"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyyzczWXBXTS"
      },
      "source": [
        "### c. Build the RAG pipeline and ask a question\n",
        "\n",
        "Let's write the three main pieces of a RAG pipeline:\n",
        "* Embedding incoming query\n",
        "* Doing similarity search to find matching chunks\n",
        "* Send chunks to LLM for completion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "zQ6rWEV2u-3U",
        "outputId": "d364b7e3-cfca-4628-da20-3ae4f34ad143"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from snowflake import connector\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from google.colab import userdata\n",
        "from typing import List\n",
        "from rich.console import Console\n",
        "\n",
        "def get_db_connection():\n",
        "    return connector.connect(\n",
        "        account=userdata.get(\"SNOWFLAKE_HOST\"),\n",
        "        role=userdata.get(\"SNOWFLAKE_ROLE\"),\n",
        "        warehouse=userdata.get(\"SNOWFLAKE_WAREHOUSE\"),\n",
        "        database=userdata.get(\"SNOWFLAKE_DATABASE\"),\n",
        "        schema=userdata.get(\"SNOWFLAKE_SCHEMA\"),\n",
        "        user=userdata.get(\"SNOWFLAKE_USERNAME\"),\n",
        "        password=userdata.get(\"SNOWFLAKE_PASSWORD\"),\n",
        "    )\n",
        "\n",
        "# convert user's query into a vector array to prep for similiary search\n",
        "def get_embedding_from_openai(query)->str:\n",
        "  print(f\"Embedding user's query -> {query}...\")\n",
        "  embeddings = OpenAIEmbeddings(openai_api_key=userdata.get(\"OPENAI_API_KEY\"))\n",
        "  return embeddings\n",
        "\n",
        "# use Snowflake's Cortex in-build similarity search to find matching chunks\n",
        "def get_similar_chunks_from_snowflake(query_vector, table_names) -> List[str]:\n",
        "        print(\"\\nRetrieving similar chunks...\")\n",
        "        conn = get_db_connection()\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        chunks = []\n",
        "        for table_name in table_names:\n",
        "            query = f\"\"\"\n",
        "            SELECT document_content,\n",
        "              VECTOR_COSINE_SIMILARITY(embedding, CAST({query_vector} AS VECTOR(FLOAT, 1536))) AS similarity\n",
        "            FROM {table_name}\n",
        "            ORDER BY similarity DESC\n",
        "            LIMIT 2\n",
        "            \"\"\"\n",
        "            cursor.execute(query)\n",
        "            result = cursor.fetchall()\n",
        "            print(f\"Found {len(result)} matching chunks in table:{table_name}!\")\n",
        "            chunks += [item[0] for item in result]\n",
        "        cursor.close()\n",
        "        conn.close()\n",
        "\n",
        "        return chunks\n",
        "\n",
        "# use Snowflake's Cortex in-build completion to find matching chunks.\n",
        "def get_completion_from_snowflake(question, document_chunks: List[str], model_name):\n",
        "        print(f\"\\nSending chunks to Snowflake (LLM: {model_name}) for completion...\")\n",
        "        conn = get_db_connection()\n",
        "        cur = conn.cursor()\n",
        "\n",
        "        chunks = \"\\n\\n\".join(document_chunks)\n",
        "\n",
        "        query = f\"\"\"\n",
        "        SELECT snowflake.cortex.complete(\n",
        "        '{model_name}',\n",
        "        CONCAT(\n",
        "            'You are an Airbyte product assistant. Answer the question based on the context. Do not use any other information. Be concise. When returning a list of items, please enumerate description on separate lines','Context: ',\n",
        "            $$\n",
        "            {chunks}\n",
        "            $$,\n",
        "        'Question: ',\n",
        "        $$ {question} $$,\n",
        "        'Answer: '\n",
        "        )\n",
        "        ) as response;\"\"\"\n",
        "        cur.execute(query)\n",
        "        result = cur.fetchall()\n",
        "        cur.close()\n",
        "        conn.close()\n",
        "        # TO-DO: better parsing here\n",
        "        return result[0][0].strip()\n",
        "\n",
        "# Putting it all together\n",
        "def get_response(query, table_names, model_name=\"llama2-70b-chat\"):\n",
        "        # Step 1: embed the query\n",
        "        embeddings = get_embedding_from_openai(query)\n",
        "\n",
        "        # Step 2: get similar chunks from sources/tables in Snowflake\n",
        "        chunks = get_similar_chunks_from_snowflake(embeddings.embed_query(query), table_names)\n",
        "\n",
        "        if (len(chunks) == 0):\n",
        "            return \"I am sorry, I do not have the context to answer your question.\"\n",
        "        else:\n",
        "            # Step 3: send chunks to LLM for completion\n",
        "            return get_completion_from_snowflake(query, chunks, model_name)\n",
        "\n",
        "# Ask a question\n",
        "query = 'How can I store vector data in Snowflake'\n",
        "response = get_response(query, [\"airbyte_docs\"], \"snowflake-arctic\")\n",
        "\n",
        "Console().print(f\"\\n\\nResponse from LLM:\\n\\n[blue]{response}[/blue]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5NvV86T57-V"
      },
      "source": [
        "### d. Let's ask another question\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "cPYdEs663tl8",
        "outputId": "6997984b-6ea3-4b95-d80f-ccace53b6d43"
      },
      "outputs": [],
      "source": [
        "query = 'What are the upcoming features for Snowflake Cortex?'\n",
        "response = get_response(query, [\"airbyte_github_issues\"])\n",
        "Console().print(f\"\\n\\nResponse from LLM:\\n\\n[blue]{response}[/blue]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_CJ3_C9pvw4"
      },
      "source": [
        "### e. Closing the loop\n",
        "Let's see if there are customers asking for upcoming features above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "mLfNlzGLqOIg",
        "outputId": "dcfa593f-dab0-44ff-fcec-e4cb671b6d1a"
      },
      "outputs": [],
      "source": [
        "query = 'Are there customers asking for better authorization options for Snowflake Cortex? Give me their names and email.'\n",
        "response = get_response(query, [\"airbyte_zendesk_tickets\", \"airbyte_zendesk_users\"])\n",
        "Console().print(f\"\\n\\nResponse from LLM:\\n\\n[blue]{response}[/blue]\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "nKbdq1eUcmAz"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
